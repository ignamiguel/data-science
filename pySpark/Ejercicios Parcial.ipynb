{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2C 2017\n",
    "# Enunciado\n",
    "Se cuenta con un RDD con información sobre patentamientos de autos con la siguiente información:\n",
    "(patente, marca, modelo,versión, tipo_vehiculo, provincia, fecha), \n",
    "donde **tipo_vehiculo** indica si la unidad patentada es auto, pickup, camión o moto.\n",
    "\n",
    "Se pide generar un programa en pySpark que indique la marca y modelo del auto más patentado por tipo de vehículo en la provincia de Buenos Aires en el mes de Abril de 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------------------------------------------------------------- ##\n",
    "## Configuración para MAC                                         ##\n",
    "## con múltiples versiones de python                              ##\n",
    "## -------------------------------------------------------------- ##\n",
    "import pyspark\n",
    "import os\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"python3.6\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"python3.6\"\n",
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName(\"sample_app\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "data_path = 'data';\n",
    "\n",
    "df_patentamientos = sqlContext.read.csv(data_path + '/patentamientos.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[12] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_patentamientos = df_patentamientos.rdd\n",
    "rdd_patentamientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(patente='AAA111', marca='VW', modelo='GOL', version='Confort-line', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_patentamientos.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(patente='AAA111', marca='VW', modelo='GOL', version='Confort-line', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='AAA222', marca='VW', modelo='GOL', version='Confort-line', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='AAA333', marca='VW', modelo='GOL', version='Trend-line', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='AAA444', marca='VW', modelo='GOL', version='Power', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='AAA555', marca='VW', modelo='GOL', version='Confort-line', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='AAA666', marca='VW', modelo='AMAROK', version='Confort-line', tipo_vehiculo='pickup', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='AAA777', marca='VW', modelo='AMAROK', version='Trend-line', tipo_vehiculo='pickup', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='AAA888', marca='VW', modelo='AMAROK', version='Power', tipo_vehiculo='pickup', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='BBB111', marca='VW', modelo='GOL', version='Confort-line', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='BBB222', marca='VW', modelo='GOL', version='Confort-line', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='BBB333', marca='VW', modelo='GOL', version='Trend-line', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='BBB444', marca='VW', modelo='GOL', version='Power', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='CCC111', marca='RENAULT', modelo='CLIO', version='Confort-line', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='CCC222', marca='RENAULT', modelo='CLIO', version='Trend-line', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='CCC333', marca='RENAULT', modelo='CLIO', version='Power', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='CCC444', marca='RENAULT', modelo='CLIO', version='Power', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='CCC555', marca='RENAULT', modelo='DUSTER', version='Confort-line', tipo_vehiculo='pickup', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='CCC666', marca='RENAULT', modelo='DUSTER', version='Trend-line', tipo_vehiculo='pickup', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='CCC777', marca='RENAULT', modelo='CLIO', version='Power', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='CCC888', marca='RENAULT', modelo='CLIO', version='Power', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='DDD111', marca='RENAULT', modelo='CLIO', version='Confort-line', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='DDD222', marca='RENAULT', modelo='CLIO', version='Trend-line', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='DDD333', marca='RENAULT', modelo='CLIO', version='Power', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='DDD444', marca='RENAULT', modelo='CLIO', version='Power', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='RRR111', marca='PEUGEOT', modelo='207', version='Full', tipo_vehiculo='auto', provincia='JUJUY', fecha='2017-04-01'),\n",
       " Row(patente='RRR222', marca='PEUGEOT', modelo='207', version='Full', tipo_vehiculo='auto', provincia='JUJUY', fecha='2017-04-01'),\n",
       " Row(patente='RRR333', marca='PEUGEOT', modelo='207', version='Full', tipo_vehiculo='auto', provincia='JUJUY', fecha='2017-05-01'),\n",
       " Row(patente='RRR444', marca='PEUGEOT', modelo='207', version='Full', tipo_vehiculo='auto', provincia='JUJUY', fecha='2017-05-01'),\n",
       " Row(patente='SSS111', marca='HONDA', modelo='207', version='Full', tipo_vehiculo='moto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='SSS222', marca='HONDA', modelo='207', version='Full', tipo_vehiculo='moto', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='TTT111', marca='SCANIA', modelo='MOD-1', version='Full', tipo_vehiculo='camión', provincia='BS AS', fecha='2017-04-01'),\n",
       " Row(patente='TTT222', marca='SCANIA', modelo='MOD-1', version='Full', tipo_vehiculo='camión', provincia='BS AS', fecha='2017-04-01')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_patentamientos.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(patente='AAA111', marca='VW', modelo='GOL', version='Confort-line', tipo_vehiculo='auto', provincia='BS AS', fecha='2017-04-01')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_patentamientos.filter(lambda a: (a[5] == \"BS AS\") and (a[6] >= \"2017-04-01\" or a[6] <= \"2017-04-30\")).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------------------------------------------------------------- ##\n",
    "## Es posible agregar .cache()                                    ##\n",
    "## para evitar el filtrado cada vez que usamos el rdd_filtered    ##\n",
    "## -------------------------------------------------------------- ##\n",
    "rdd_filtered = rdd_patentamientos.filter(lambda a: (a[5] == \"BS AS\") and (a[6] >= \"2017-04-01\" or a[6] <= \"2017-04-30\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_grouped = rdd_filtered.map(lambda x: ((x[1], x[2], x[3], x[4]), 1))\\\n",
    "            .reduceByKey(lambda x, y: x + y)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('VW', 'GOL', 'Confort-line', 'auto'), 5),\n",
       " (('VW', 'GOL', 'Trend-line', 'auto'), 2),\n",
       " (('VW', 'GOL', 'Power', 'auto'), 2),\n",
       " (('VW', 'AMAROK', 'Confort-line', 'pickup'), 1),\n",
       " (('VW', 'AMAROK', 'Trend-line', 'pickup'), 1),\n",
       " (('VW', 'AMAROK', 'Power', 'pickup'), 1),\n",
       " (('RENAULT', 'CLIO', 'Confort-line', 'auto'), 2),\n",
       " (('RENAULT', 'CLIO', 'Trend-line', 'auto'), 2),\n",
       " (('RENAULT', 'CLIO', 'Power', 'auto'), 6),\n",
       " (('RENAULT', 'DUSTER', 'Confort-line', 'pickup'), 1),\n",
       " (('RENAULT', 'DUSTER', 'Trend-line', 'pickup'), 1),\n",
       " (('HONDA', '207', 'Full', 'moto'), 2),\n",
       " (('SCANIA', 'MOD-1', 'Full', 'camión'), 2)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_grouped.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('VW', 'GOL', 'auto'), ('Confort-line', 5)),\n",
       " (('VW', 'GOL', 'auto'), ('Trend-line', 2)),\n",
       " (('VW', 'GOL', 'auto'), ('Power', 2)),\n",
       " (('VW', 'AMAROK', 'pickup'), ('Confort-line', 1)),\n",
       " (('VW', 'AMAROK', 'pickup'), ('Trend-line', 1)),\n",
       " (('VW', 'AMAROK', 'pickup'), ('Power', 1)),\n",
       " (('RENAULT', 'CLIO', 'auto'), ('Confort-line', 2)),\n",
       " (('RENAULT', 'CLIO', 'auto'), ('Trend-line', 2)),\n",
       " (('RENAULT', 'CLIO', 'auto'), ('Power', 6)),\n",
       " (('RENAULT', 'DUSTER', 'pickup'), ('Confort-line', 1)),\n",
       " (('RENAULT', 'DUSTER', 'pickup'), ('Trend-line', 1)),\n",
       " (('HONDA', '207', 'moto'), ('Full', 2)),\n",
       " (('SCANIA', 'MOD-1', 'camión'), ('Full', 2))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_grouped.map(lambda x: ((x[0][0], x[0][1], x[0][3]), (x[0][2], x[1]))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_max = rdd_grouped.map(lambda x: ((x[0][0], x[0][1], x[0][3]), (x[0][2], x[1])))\\\n",
    "           .reduceByKey(lambda x, y: x if (x[1] >= y[1]) else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_max.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('VW', 'GOL', 'auto'), ('Confort-line', 5)),\n",
       " (('VW', 'AMAROK', 'pickup'), ('Confort-line', 1)),\n",
       " (('RENAULT', 'CLIO', 'auto'), ('Power', 6)),\n",
       " (('RENAULT', 'DUSTER', 'pickup'), ('Confort-line', 1)),\n",
       " (('HONDA', '207', 'moto'), ('Full', 2)),\n",
       " (('SCANIA', 'MOD-1', 'camión'), ('Full', 2))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_max.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------\n",
    "---------------------------------------------------------------------------------------\n",
    "# 1C 2017\n",
    "# Enunciado\n",
    "\n",
    "Se tiene información estadística de la temporada regular de todos los jugadores de la NBA en un RDD de tuplas con el siguiente formato:\n",
    "\n",
    "```\n",
    "(id_jugador, nombre, promedio_puntos, promedio_asistencias, promedio_robos, promedio_bloqueos, promedio_rebotes, promedio_faltas) \n",
    "```\n",
    "\n",
    "Un analista de la cadena ESPN está trabajando con un RDD que corresponde a la primera ronda de playoffs y que tiene el siguiente formato: \n",
    "\n",
    "```\n",
    "(id_jugador, id_partido, timestamp, cantidad_puntos, cantidad_rebotes, cantidad_bloqueos, cantidad_robos, cantidad_asistencias, cantidad_faltas) \n",
    "```\n",
    "\n",
    "En base a estos RDDs se quiere programar en PySpark un programa que genere un RDD con los nombres (sin duplicados) de los jugadores que lograron en algún partido de playoffs una cantidad de asistencias mayor a su promedio histórico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporada_regular = [\n",
    "    (\"1938\", \"Emanuel Ginobili\", 8.9, 2.5, 2.2, 15.9, 2.2, 3.4),\n",
    "    (\"2544\", \"LeBron James\", 27.5, 9.1, 1.9, 9.4, 9.1, 2.4),\n",
    "    (\"201142\", \"Kevin Durant\", 26.4, 5.4, 1.9, 1.0, 8.0, 1.7),\n",
    "    (\"201566\", \"Russell Westbrook\", 25.4, 10.3, 1.5, 1.0, 12.0, 3.5)\n",
    "]\n",
    "\n",
    "playoffs = [\n",
    "    (\"1938\", \"1\", 1526245886, 10, 2, 2, 15, 2, 3),\n",
    "    (\"2544\", \"1\", 1526245886, 27, 9, 1, 9, 9, 2),\n",
    "    (\"201142\", \"2\", 1526245886, 25, 10, 1, 1, 9, 2),\n",
    "    (\"201566\", \"2\", 1526245886, 27, 9, 1, 9, 9, 2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporada_regular_rdd = sc.parallelize(temporada_regular)\n",
    "playoffs_rdd = sc.parallelize(playoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_asist_hist = temporada_regular_rdd.map(lambda x: (x[0], (x[1], x[3])))\n",
    "rdd_asist_playoffs = playoffs_rdd.map(lambda x: (x[0], (x[1], x[7])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1938', ('Emanuel Ginobili', 2.5)),\n",
       " ('2544', ('LeBron James', 9.1)),\n",
       " ('201142', ('Kevin Durant', 5.4)),\n",
       " ('201566', ('Russell Westbrook', 10.3))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_asist_hist.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1938', ('1', 2)),\n",
       " ('2544', ('1', 9)),\n",
       " ('201142', ('2', 9)),\n",
       " ('201566', ('2', 9))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_asist_playoffs.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_joined = rdd_asist_playoffs.join(rdd_asist_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2544', (('1', 9), ('LeBron James', 9.1))),\n",
       " ('1938', (('1', 2), ('Emanuel Ginobili', 2.5))),\n",
       " ('201142', (('2', 9), ('Kevin Durant', 5.4))),\n",
       " ('201566', (('2', 9), ('Russell Westbrook', 10.3)))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_joined.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('201142', (('2', 9), ('Kevin Durant', 5.4)))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_joined.filter(lambda x: x[1][0][1] >= x[1][1][1]).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------\n",
    "---------------------------------------------------------------------------------------\n",
    "\n",
    "# 2C 2016\n",
    "# Enunciado\n",
    "\n",
    "Contamos con un cluster que tiene 4 computadoras. Queremos aprovechar el paralelismo del cluster para calcular los números primos entre 2 y 20.000.000. Para esto usaremos el conocido algoritmo de la criba de Eratóstenes. Por ejemplo si empezamos con una lista de tipo (2,3,4,5,6,7,8...) en un primer paso eliminamos todos los que son mayores a 2 y divisibles por 2 y nos queda (2,3,5,7,9,11,13…) luego eliminamos todos los mayores a 3 divisibles por 3 y nos queda (2,3,5,7,11,13….etc) luego todos los divisibles por 5 y así sucesivamente. El resultado final es una lista de números que son primos. Programar este programa usando PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000000.0\n"
     ]
    }
   ],
   "source": [
    "maxVal = 20e6\n",
    "print(maxVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199]\n"
     ]
    }
   ],
   "source": [
    "maxVal = 200#e6\n",
    "rdd = sc.parallelize(range(2,maxVal+1))\n",
    "primes = []\n",
    "\n",
    "while(rdd.count() > 0):\n",
    "    minval = rdd.reduce(lambda x,y: x if (x < y) else y)\n",
    "    def isNotDivisible(n, div=minval):\n",
    "        return n%div != 0\n",
    "    rdd = rdd.filter(isNotDivisible)\n",
    "    primes.append(minval)\n",
    "print(primes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------\n",
    "---------------------------------------------------------------------------------------\n",
    "\n",
    "# 1C 2016\n",
    "# Enunciado\n",
    "UBER almacena en un cluster todos los datos sobre el movimiento y viajes de todos sus vehículos.\n",
    "\n",
    "Existe un proceso que nos devuelve un RDD llamado **trip_summary** con los siguientes campos: (driver_id, car_id, trip_id, customer_id, date (YYYYMMDD), distance_traveled)\n",
    "\n",
    "Programar usando Py Spark un programa que nos indique cual fue el conductor con mayor promedio de distancia recorrida por viaje para Abril de 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_summary = [\n",
    "    (\"driver-1\", \"car-1\", \"trip-1\", \"customer Pepe\", \"20160401\", 10),\n",
    "    (\"driver-2\", \"car-2\", \"trip-2\", \"customer Lalo\", \"20160401\", 5),\n",
    "    (\"driver-3\", \"car-3\", \"trip-3\", \"customer Pablo\", \"20160401\", 7),\n",
    "    (\"driver-1\", \"car-1\", \"trip-4\", \"customer Paco\", \"20160402\", 3),\n",
    "    (\"driver-2\", \"car-2\", \"trip-5\", \"customer Fito\", \"20160402\", 12),\n",
    "    (\"driver-4\", \"car-4\", \"trip-6\", \"customer Facu\", \"20160401\", 14),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize(trip_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('driver-1', 'car-1', 'trip-1', 'customer Pepe', '20160401', 10),\n",
       " ('driver-2', 'car-2', 'trip-2', 'customer Lalo', '20160401', 5),\n",
       " ('driver-3', 'car-3', 'trip-3', 'customer Pablo', '20160401', 7),\n",
       " ('driver-1', 'car-1', 'trip-4', 'customer Paco', '20160402', 3),\n",
       " ('driver-2', 'car-2', 'trip-5', 'customer Fito', '20160402', 12),\n",
       " ('driver-4', 'car-4', 'trip-6', 'customer Facu', '20160401', 14)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtrar los viajes de Abril 2016\n",
    "rdd_filtered = data.filter(lambda x: (x[4] >= \"20160401\") and (x[4] <= \"20160430\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('driver-1', 'car-1', 'trip-1', 'customer Pepe', '20160401', 10),\n",
       " ('driver-2', 'car-2', 'trip-2', 'customer Lalo', '20160401', 5),\n",
       " ('driver-3', 'car-3', 'trip-3', 'customer Pablo', '20160401', 7),\n",
       " ('driver-1', 'car-1', 'trip-4', 'customer Paco', '20160402', 3),\n",
       " ('driver-2', 'car-2', 'trip-5', 'customer Fito', '20160402', 12),\n",
       " ('driver-4', 'car-4', 'trip-6', 'customer Facu', '20160401', 14)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_filtered.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agrupar los drivers, sumando distancia y contando cantidad de viajes\n",
    "rdd_drivers = rdd_filtered.map(lambda x: (x[0], (x[5], 1)))\\\n",
    "            .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Opcional: filtar por los drivers que tengan >= n viajes\n",
    "n = 1\n",
    "rdd_drivers_filtered = rdd_drivers.filter(lambda x: x[1][1] >= n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('driver-1', (13, 2)),\n",
       " ('driver-4', (14, 1)),\n",
       " ('driver-2', (17, 2)),\n",
       " ('driver-3', (7, 1))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_drivers_filtered.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('driver-4', 14.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reducir hasta quedarme con el driver con mayor promedio de distancia recorrida\n",
    "rdd_drivers_filtered.map(lambda x: (x[0], x[1][0]/x[1][1]))\\\n",
    "                    .reduce(lambda x, y: x if (x[1] >= y[1]) else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
